<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Conference Template</title>


</head>

<body>

    <div class="banner">
        <img src="cover_img.png" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">AVVision</span><span class="title2">2021</span> 
        </div>
        <div class="bottom-right">
            January 5 - 9, 2021 <br> In Conjunction with WACV 2021
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Conference Program" href="committee">Committees</a> 
            </td>
            <td class="navigation">
                <a title="Conference Program" href="program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td>
            <td class="navigation">
                <a title="Conference Flyer" href="flyer">Flyer</a>
            </td>
        </tr>
    </table>

    <h2>Autonomous Vehicle Vision 2021 (AVVision'21)</h2>
    <p>
    The Autonomous Vehicle Vision 2021 (AVVision’21) workshop aims to gather researchers and engineers from both academia and industry to discuss the latest advances in autonomous vehicle visual perception. In this one-day workshop, we will have regular paper presentations, invited speakers, and technical challenges, to present the state of the art as well as the challenges in autonomous vehicle perception, localization and mapping. We plan to host several challenges to understand the current status of computer vision algorithms in solving the environmental perception problems for autonomous driving. We have prepared a number of large-scale, synthetic/real-world datasets with annotations by Hong Kong University of Science and Technology (HKUST), CalmCar, UDI, ATG Robotics, etc. Based on these datasets, three challenges will be hosted. Specifically, they are HKUST-UDI UDA Challenge (unsupervised domain adaptation from synthetic scenarios to real-world scenarios) and CalmCar Multi-Object Tracking Challenge (car tracking and ego-motion estimation). 
    </p>

    <h2>Call for Papers</h2>
    <p>
With a number of breakthroughs in autonomous system technology over the past decade, the race to commercialize self-driving cars has become fiercer than ever. The integration of advanced sensing, computer vision, signal/image processing, and machine/deep learning into autonomous vehicles enables them to perceive the environment intelligently and navigate safely. In particular, autonomous driving and, more generally, automated driving enables safe, reliable, and efficient automated mobility in complex uncontrolled real-world environments. Various applications range from automated transportation and farming to public safety and environment exploration. Visual perception is a critical component of autonomous driving. Enabling technologies are: a) affordable sensors that can acquire useful data under varying environmental conditions, b) reliable simultaneous localization and mapping, c) machine learning that can effectively handle varying real-world conditions and unforeseen events, “machine-learning friendly” signal processing to enable more effective classification and decision making, d) hardware and software co-design for efficient real-time performance, e) resilient and robust platforms that can withstand adversarial attacks and failures, and f) end-to-end system integration of sensing, computer vision, signal/image processing and machine/deep learning. The proposed workshop will cover all these topics. Research papers are solicited in, but not limited to, the following topic areas:
 <p>
     

        <ul>
<li>3D road/environment reconstruction and understanding</li>
<li>Mapping and localization for autonomous cars</li>
<li>Semantic/instance driving scene segmentation and semantic mapping</li>
<li>Self-supervised/unsupervised visual environment perception</li>
<li>Car/pedestrian/object/obstacle detection/tracking and 3D localization</li> 
<li>Car/license plate/road sign detection and recognition</li>
<li>Driver status monitoring and human-car interfaces</li>
<li>Deep/machine learning and image analysis for car perception</li>
<li>Adversarial domain adaptation for autonomous driving</li>
<li>On-board embedded visual perception systems</li>
<li>Bio-inspired vision sensing for car perception</li>
<li>Real-time deep learning inference</li>
    </ul>


    
    
        <div class="banner">
        <img src="partners.png" alt="Conference Template Banner">
    </div>
    
   

    </body>
</html>
